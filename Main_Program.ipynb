{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c817e5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23be7158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db8b6ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datasets import letterbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be188c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.general import non_max_suppression_kpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd6a3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48a6a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install tk\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe5b103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d108f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#We can load the model from the weight file with torch.load().\n",
    "#Let's create a function to check if a GPU is available, load the model,\n",
    "#put it in inference mode and move it to the GPU if available:\n",
    "def load_model():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.load('yolov7-w6-pose.pt', map_location=device)['model']\n",
    "    # Put in inference mode\n",
    "    model.float().eval()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        # half() turns predictions into float16 tensors\n",
    "        # which significantly lowers inference time\n",
    "        model.half().to(device)\n",
    "    return model\n",
    "\n",
    "model = load_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9915e4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(url):\n",
    "    image = cv2.imread(url) # shape: (480, 640, 3)\n",
    "    # Resize and pad image\n",
    "    image = letterbox(image, 960, stride=64, auto=True)[0] # shape: (768, 960, 3)\n",
    "    # Apply transforms\n",
    "    image = transforms.ToTensor()(image) # torch.Size([3, 768, 960])\n",
    "    # Turn image into batch\n",
    "    image = image.unsqueeze(0) # torch.Size([1, 3, 768, 960])\n",
    "    output, _ = model(image) # torch.Size([1, 45900, 57])\n",
    "    return output, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f3a999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_output(output, image):\n",
    "    output = non_max_suppression_kpt(output,\n",
    "                                     0.25, # Confidence Threshold\n",
    "                                     0.65, # IoU Threshold\n",
    "                                     nc=model.yaml['nc'], # Number of Classes\n",
    "                                     nkpt=model.yaml['nkpt'], # Number of Keypoints\n",
    "                                     kpt_label=True)\n",
    "    with torch.no_grad():\n",
    "        output = output_to_keypoint(output)\n",
    "    nimg = image[0].permute(1, 2, 0) * 255\n",
    "    nimg = nimg.cpu().numpy().astype(np.uint8)\n",
    "    nimg = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)\n",
    "    for idx in range(output.shape[0]):\n",
    "        plot_skeleton_kpts(nimg, output[idx, 7:].T, 3)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(nimg)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4f1518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, image = run_inference('Shakira_Jimmy.jpg')\n",
    "\n",
    "visualize_output(output, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5229768a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
